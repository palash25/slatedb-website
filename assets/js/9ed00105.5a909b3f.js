"use strict";(self.webpackChunkslatedb_website=self.webpackChunkslatedb_website||[]).push([[873],{2163:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var o=t(4848),i=t(8453);const s={sidebar_position:3},r="Configuration",a={id:"configuration",title:"Configuration",description:"Database Options",source:"@site/docs/configuration.md",sourceDirName:".",slug:"/configuration",permalink:"/docs/configuration",draft:!1,unlisted:!1,editUrl:"https://github.com/slatedb/slatedb-website/tree/main/docs/configuration.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"docsSidebar",previous:{title:"Connect SlateDB to S3",permalink:"/docs/tutorials/s3"},next:{title:"Architecture",permalink:"/docs/architecture"}},l={},c=[{value:"Database Options",id:"database-options",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",pre:"pre",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"configuration",children:"Configuration"}),"\n",(0,o.jsx)(n.h2,{id:"database-options",children:"Database Options"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:'/// Configuration options for the database. These options are set on client startup.\n#[derive(Clone)]\npub struct DbOptions {\n    /// How frequently to flush the write-ahead log to object storage.\n    ///\n    /// When setting this configuration, users must consider:\n    ///\n    /// * **Latency**: The higher the flush interval, the longer it will take for\n    ///   writes to be committed to object storage. Writers blocking on `put` calls\n    ///   will wait longer for the write. Readers reading committed writes will also\n    ///   see data later.\n    /// * **API cost**: The lower the flush interval, the more frequently PUT calls\n    ///   will be made to object storage. This can increase your object storage costs.\n    ///\n    /// We recommend setting this value based on your cost and latency tolerance. A\n    /// 100ms flush interval should result in $130/month in PUT costs on S3 standard.\n    ///\n    /// Keep in mind that the flush interval does not include the network latency. A\n    /// 100ms flush interval will result in a 100ms + the time it takes to send the\n    /// bytes to object storage.\n    pub flush_interval: Duration,\n\n    /// If set to false, SlateDB will disable the WAL and write directly into the memtable\n    #[cfg(feature = "wal_disable")]\n    pub wal_enabled: bool,\n\n    /// How frequently to poll for new manifest files. Refreshing the manifest file\n    /// allows writers to detect fencing operations and allows readers to detect newly\n    /// compacted data.\n    ///\n    /// **NOTE: SlateDB secondary readers (i.e. non-writer clients) do not currently\n    /// read from the WAL. Such readers only read from L0+. The manifest poll intervals\n    /// allows such readers to detect new L0+ files.**\n    pub manifest_poll_interval: Duration,\n\n    /// Write SSTables with a bloom filter if the number of keys in the SSTable\n    /// is greater than or equal to this value. Reads on small SSTables might be\n    /// faster without a bloom filter.\n    pub min_filter_keys: u32,\n\n    /// The minimum size a memtable needs to be before it is frozen and flushed to\n    /// L0 object storage. Writes will still be flushed to the object storage WAL\n    /// (based on flush_interval) regardless of this value. Memtable sizes are checked\n    /// every `flush_interval`.\n    ///\n    /// When setting this configuration, users must consider:\n    ///\n    /// * **Recovery time**: The larger the L0 SSTable size threshold, the less\n    ///   frequently it will be written. As a result, the more recovery data there\n    ///   will be in the WAL if a process restarts.\n    /// * **Number of L0 SSTs/SRs**: The smaller the L0 SSTable size threshold, the\n    ///   more SSTs and Sorted Runs there will be. L0 SSTables are not range\n    ///   partitioned; each is its own sorted table. Similarly, each Sorted Run also\n    ///   stores the entire keyspace. As such, reads that don\'t hit the WAL or memtable\n    ///   may need to scan all L0 SSTables and Sorted Runs. The more there are, the\n    ///   slower the scan will be.\n    /// * **Memory usage**: The larger the L0 SSTable size threshold, the larger the\n    ///   unflushed in-memory memtable will grow. This shouldn\'t be a concern for most\n    ///   workloads, but it\'s worth considering for workloads with very high L0\n    ///   SSTable sizes.\n    /// * **API cost**: Smaller L0 SSTable sizes will result in more frequent writes\n    ///   to object storage. This can increase your object storage costs.\n    /// * **Secondary reader latency**: Secondary (non-writer) clients only see L0+\n    ///   writes; they don\'t see WAL writes. Thus, the higher the L0 SSTable size, the\n    ///   less frequently they will be written, and the longer it will take for\n    ///   secondary readers to see new data.\n    pub l0_sst_size_bytes: usize,\n\n    /// Defines the max number of SSTs in l0. Memtables will not be flushed if there are more\n    /// l0 ssts than this value, until compaction can compact the ssts into compacted.\n    pub l0_max_ssts: usize,\n\n    /// Defines the max number of unflushed memtables. Writes will be paused if there\n    /// are more unflushed memtables than this value\n    pub max_unflushed_memtable: usize,\n\n    /// Configuration options for the compactor.\n    pub compactor_options: Option<CompactorOptions>,\n    pub compression_codec: Option<CompressionCodec>,\n}\n\nimpl Default for DbOptions {\n    fn default() -> Self {\n        Self {\n            flush_interval: Duration::from_millis(100),\n            #[cfg(feature = "wal_disable")]\n            wal_enabled: true,\n            manifest_poll_interval: Duration::from_secs(1),\n            min_filter_keys: 1000,\n            l0_sst_size_bytes: 64 * 1024 * 1024,\n            max_unflushed_memtable: 2,\n            l0_max_ssts: 8,\n            compactor_options: Some(CompactorOptions::default()),\n            compression_codec: None,\n        }\n    }\n}\n\n/// The compression algorithm to use for SSTables.\n#[derive(Clone, Copy, Debug)]\npub enum CompressionCodec {\n    #[cfg(feature = "snappy")]\n    /// Snappy compression algorithm.\n    Snappy,\n    #[cfg(feature = "zlib")]\n    /// Zlib compression algorithm.\n    Zlib,\n    #[cfg(feature = "lz4")]\n    /// Lz4 compression algorithm.\n    Lz4,\n    #[cfg(feature = "zstd")]\n    /// Zstd compression algorithm.\n    Zstd,\n}\n\nimpl FromStr for CompressionCodec {\n    type Err = SlateDBError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s {\n            #[cfg(feature = "snappy")]\n            "snappy" => Ok(Self::Snappy),\n            #[cfg(feature = "zlib")]\n            "zlib" => Ok(Self::Zlib),\n            #[cfg(feature = "lz4")]\n            "lz4" => Ok(Self::Lz4),\n            #[cfg(feature = "zstd")]\n            "zstd" => Ok(Self::Zstd),\n            _ => Err(SlateDBError::InvalidCompressionCodec),\n        }\n    }\n}\n\npub trait CompactionSchedulerSupplier: Send + Sync {\n    fn compaction_scheduler(&self) -> Box<dyn CompactionScheduler>;\n}\n\n/// Options for the compactor.\n#[derive(Clone)]\npub struct CompactorOptions {\n    /// The interval at which the compactor checks for a new manifest and decides\n    /// if a compaction must be scheduled\n    pub poll_interval: Duration,\n\n    /// A compacted SSTable\'s maximum size (in bytes). If more data needs to be\n    /// written to a Sorted Run during a compaction, a new SSTable will be created\n    /// in the Sorted Run when this size is exceeded.\n    pub max_sst_size: usize,\n\n    /// Supplies the compaction scheduler to use to select the compactions that should be\n    /// scheduled. Currently, the only provided implementation is\n    /// SizeTieredCompactionSchedulerSupplier\n    pub compaction_scheduler: Arc<dyn CompactionSchedulerSupplier>,\n\n    /// The maximum number of concurrent compactions to execute at once\n    pub max_concurrent_compactions: usize,\n}\n\n/// Default options for the compactor. Currently, only a\n/// `SizeTieredCompactionScheduler` compaction strategy is implemented.\nimpl Default for CompactorOptions {\n    /// Returns a `CompactorOptions` with a 5 second poll interval and a 1GB max\n    /// SSTable size.\n    fn default() -> Self {\n        Self {\n            poll_interval: Duration::from_secs(5),\n            max_sst_size: 1024 * 1024 * 1024,\n            compaction_scheduler: Arc::new(SizeTieredCompactionSchedulerSupplier::new(\n                SizeTieredCompactionSchedulerOptions::default(),\n            )),\n            max_concurrent_compactions: 4,\n        }\n    }\n}\n\n#[derive(Clone)]\n/// Options for the Size-Tiered Compaction Scheduler\npub struct SizeTieredCompactionSchedulerOptions {\n    /// The minimum number of sources to include together in a single compaction step.\n    pub min_compaction_sources: usize,\n    /// The maximum number of sources to include together in a single compaction step.\n    pub max_compaction_sources: usize,\n    /// The size threshold that the scheduler will use to determine if a sorted run should\n    /// be included in a given compaction. A sorted run S will be added to a compaction C if S\'s\n    /// size is less than this value times the min size of the runs currently included in C.\n    pub include_size_threshold: f32,\n}\n\nimpl SizeTieredCompactionSchedulerOptions {\n    pub const fn default() -> Self {\n        Self {\n            min_compaction_sources: 4,\n            max_compaction_sources: 8,\n            include_size_threshold: 4.0,\n        }\n    }\n}\n\n/// Whether reads see only writes that have been committed durably to the DB.  A\n/// write is considered durably committed if all future calls to read are guaranteed\n/// to serve the data written by the write, until some later durably committed write\n/// updates the same key.\npub enum ReadLevel {\n    /// Client reads will only see data that\'s been committed durably to the DB.\n    Commited,\n\n    /// Clients will see all writes, including those not yet durably committed to the\n    /// DB.\n    Uncommitted,\n}\n\n/// Configuration for client read operations. `ReadOptions` is supplied for each\n/// read call and controls the behavior of the read.\npub struct ReadOptions {\n    /// The read commit level for read operations.\n    pub read_level: ReadLevel,\n}\n\nimpl ReadOptions {\n    /// Create a new ReadOptions with `read_level` set to `Commited`.\n    const fn default() -> Self {\n        Self {\n            read_level: ReadLevel::Commited,\n        }\n    }\n}\n\n/// Configuration for client write operations. `WriteOptions` is supplied for each\n/// write call and controls the behavior of the write.\n#[derive(Clone)]\npub struct WriteOptions {\n    /// Whether `put` calls should block until the write has been durably committed\n    /// to the DB.\n    pub await_durable: bool,\n}\n\nimpl WriteOptions {\n    /// Create a new `WriteOptions`` with `await_durable` set to `true`.\n    const fn default() -> Self {\n        Self {\n            await_durable: true,\n        }\n    }\n}\n\n'})})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var o=t(6540);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);